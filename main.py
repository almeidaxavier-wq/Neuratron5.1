import torch
import torch.nn as nn
import torch.nn.functional as F
from neura.neuratron import Neuratron  # Importe sua classe aqui

def test_initialization():
    """Testa se o Neuratron inicializa corretamente"""
    print("=== Teste de Inicializa√ß√£o ===")
    
    total_size = (100, 50)
    model = Neuratron(total_size)
    
    # Verifica se os par√¢metros foram criados
    assert model.total_weight.shape == (50, 100), f"Peso total shape errado: {model.total_weight.shape}"
    assert model.total_bias.shape == (50,), f"Bias total shape errado: {model.total_bias.shape}"
    
    # Verifica se h√° 1 bloco livre inicial
    assert len(model.free_blocks) == 1, f"Blocos livres iniciais: {len(model.free_blocks)}"
    assert model.free_blocks[0] == ((0, 100), (0, 50)), f"Bloco livre inicial errado: {model.free_blocks[0]}"
    
    print("‚úÖ Inicializa√ß√£o OK")

def test_basic_allocation():
    """Testa uma aloca√ß√£o b√°sica"""
    print("\n=== Teste de Aloca√ß√£o B√°sica ===")
    
    model = Neuratron((100, 50))
    
    # Aloca uma camada 20x10
    success = model.allocate("camada1", 20, 10)
    assert success, "Falha na aloca√ß√£o"
    
    # Verifica se a aloca√ß√£o foi registrada
    assert "camada1" in model.allocations, "Aloca√ß√£o n√£o registrada"
    
    # Verifica os √≠ndices da aloca√ß√£o
    alloc = model.allocations["camada1"]
    assert alloc == ((0, 20), (0, 10)), f"Aloca√ß√£o errada: {alloc}"
    
    # Verifica se criou blocos livres
    assert len(model.free_blocks) >= 1, f"Deve ter pelo menos 1 bloco livre, got {len(model.free_blocks)}"
    
    print("‚úÖ Aloca√ß√£o b√°sica OK")
    model.print_memory_map()

def test_forward_pass():
    """Testa se o forward pass funciona"""
    print("\n=== Teste de Forward Pass ===")
    
    model = Neuratron((10, 5))
    model.allocate("test_layer", 3, 2)
    
    # Pega os pesos manualmente para verifica√ß√£o
    weight, bias = model.get_layer("test_layer")
    assert weight.shape == (2, 3), f"Peso shape errado: {weight.shape}"
    assert bias.shape == (2,), f"Bias shape errado: {bias.shape}"
    
    # Testa o forward
    x = torch.randn(4, 3)  # batch_size=4, input_size=3
    output = model.forward(x, "test_layer")
    
    assert output.shape == (4, 2), f"Output shape errado: {output.shape}"
    
    # Verifica manualmente a opera√ß√£o linear
    expected_output = x @ weight.T + bias
    torch.testing.assert_close(output, expected_output)
    
    print("‚úÖ Forward pass OK")

def test_training():
    """Testa se o treinamento funciona"""
    print("\n=== Teste de Treinamento ===")
    
    model = Neuratron((10, 8))
    model.allocate("train_layer", 5, 3)
    
    # Configura otimizador
    optimizer = torch.optim.SGD(model.parameters(), lr=0.01)
    
    # Dados de exemplo
    x = torch.randn(8, 5)
    y_target = torch.randn(8, 3)
    
    # Loop de treino simples
    initial_loss = None
    for epoch in range(5):
        optimizer.zero_grad()
        output = model.forward(x, "train_layer")
        loss = F.mse_loss(output, y_target)
        loss.backward()
        optimizer.step()
        
        if initial_loss is None:
            initial_loss = loss.item()
        
        print(f"√âpoca {epoch}, Loss: {loss.item():.4f}")
    
    # Verifica se o loss diminuiu
    final_loss = loss.item()
    assert final_loss < initial_loss, f"Loss n√£o diminuiu: {initial_loss} -> {final_loss}"
    
    print("‚úÖ Treinamento OK")

# Executa os testes
if __name__ == "__main__":
    print("üß™ Testando Neuratron...")
    
    try:
        test_initialization()
        test_basic_allocation()
        test_forward_pass()
        test_training()
        print("\nüéâ Todos os testes passaram!")
        
    except Exception as e:
        print(f"\n‚ùå Erro durante os testes: {e}")
        import traceback
        traceback.print_exc()