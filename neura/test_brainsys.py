import torch
import torch.nn as nn
import torch.nn.functional as F
import torch.optim as optim
import numpy as np
import random
import sys
import os

# Adiciona o diretÃ³rio atual ao path para importar os mÃ³dulos
sys.path.insert(0, os.path.dirname(os.path.abspath(__file__)))

from neuratron import Neuratron
from brainsys import BrainSys

class TestNeuratron:
    """Testes para a classe Neuratron"""
    
    def test_initialization(self):
        """Testa a inicializaÃ§Ã£o do Neuratron"""
        print("ðŸ§ª Testando inicializaÃ§Ã£o do Neuratron...")
        
        total_size = (100, 50)
        model = Neuratron(total_size)
        
        # Verifica shapes dos parÃ¢metros
        assert model.total_weight.shape == (50, 100)
        assert model.total_bias.shape == (50,)
        
        # Verifica blocos livres iniciais
        assert len(model.free_blocks) == 1
        assert model.free_blocks[0] == ((0, 100), (0, 50))
        
        print("âœ… Neuratron inicializado corretamente")

    def test_basic_allocation(self):
        """Testa alocaÃ§Ã£o bÃ¡sica"""
        print("ðŸ§ª Testando alocaÃ§Ã£o bÃ¡sica...")
        
        model = Neuratron((100, 50))
        
        # Aloca uma camada
        success = model.allocate("camada_teste", 20, 10)
        assert success
        
        # Verifica se a alocaÃ§Ã£o foi registrada
        assert "camada_teste" in model.allocations
        assert model.allocations["camada_teste"] == ((0, 20), (0, 10))
        
        # Verifica que blocos livres foram criados
        assert len(model.free_blocks) >= 1
        
        print("âœ… AlocaÃ§Ã£o bÃ¡sica funcionando")

    def test_forward_pass(self):
        """Testa o forward pass"""
        print("ðŸ§ª Testando forward pass...")
        
        model = Neuratron((10, 5))
        model.allocate("test_layer", 3, 2)
        
        # Testa forward pass
        x = torch.randn(4, 3)
        output = model.forward(x, "test_layer")
        
        assert output.shape == (4, 2)
        
        # Verifica cÃ¡lculo manual
        weight, bias = model.get_layer("test_layer")
        expected = F.linear(x, weight, bias)
        torch.testing.assert_close(output, expected)
        
        print("âœ… Forward pass funcionando")

    def test_multiple_allocations(self):
        """Testa mÃºltiplas alocaÃ§Ãµes"""
        print("ðŸ§ª Testando mÃºltiplas alocaÃ§Ãµes...")
        
        model = Neuratron((100, 100))
        
        # Aloca vÃ¡rias camadas
        model.allocate("layer1", 30, 20)
        model.allocate("layer2", 25, 15)
        model.allocate("layer3", 40, 10)
        
        assert len(model.allocations) == 3
        assert "layer1" in model.allocations
        assert "layer2" in model.allocations
        assert "layer3" in model.allocations
        
        print("âœ… MÃºltiplas alocaÃ§Ãµes funcionando")

    def test_allocation_failure(self):
        """Testa falha de alocaÃ§Ã£o quando nÃ£o hÃ¡ espaÃ§o"""
        print("ðŸ§ª Testando falha de alocaÃ§Ã£o...")
        
        model = Neuratron((10, 10))
        
        # Aloca quase todo o espaÃ§o
        model.allocate("big_layer", 9, 9)
        
        # Deve falhar ao tentar alocar mais
        try:
            model.allocate("should_fail", 5, 5)
            assert False, "Deveria ter falhado"
        except RuntimeError as e:
            assert "NÃ£o hÃ¡ espaÃ§o suficiente" in str(e)
        
        print("âœ… Falha de alocaÃ§Ã£o funcionando corretamente")

    def test_training_compatibility(self):
        """Testa compatibilidade com treinamento"""
        print("ðŸ§ª Testando compatibilidade com treinamento...")
        
        model = Neuratron((10, 8))
        model.allocate("train_layer", 5, 3)
        
        # Verifica se os parÃ¢metros sÃ£o acessÃ­veis
        params = list(model.parameters())
        assert len(params) == 2
        
        # Testa otimizador
        optimizer = torch.optim.SGD(model.parameters(), lr=0.01)
        
        x = torch.randn(8, 5)
        y_target = torch.randn(8, 3)
        
        # Loop de treino simples
        for epoch in range(2):
            optimizer.zero_grad()
            output = model.forward(x, "train_layer")
            loss = F.mse_loss(output, y_target)
            loss.backward()
            optimizer.step()
        
        print("âœ… Compatibilidade com treinamento OK")

    def run_all_tests(self):
        """Executa todos os testes do Neuratron"""
        print("\n" + "="*60)
        print("ðŸš€ INICIANDO TESTES DO NEURATRON")
        print("="*60)
        
        tests = [
            self.test_initialization,
            self.test_basic_allocation,
            self.test_forward_pass,
            self.test_multiple_allocations,
            self.test_allocation_failure,
            self.test_training_compatibility
        ]
        
        for test in tests:
            try:
                test()
            except Exception as e:
                print(f"âŒ {test.__name__} FALHOU: {e}")
                raise
        
        print("\nðŸŽ‰ TODOS OS TESTES DO NEURATRON PASSARAM!")

class TestBrainSys:
    """Testes para a classe BrainSys"""
    
    def test_brainsys_initialization(self):
        """Testa inicializaÃ§Ã£o do BrainSys"""
        print("ðŸ§ª Testando inicializaÃ§Ã£o do BrainSys...")
        
        neuratron = Neuratron((100, 50))
        optimizer = torch.optim.Adam(neuratron.parameters(), lr=0.001)
        
        brain = BrainSys(neuratron, optimizer)
        
        assert brain.layers == neuratron
        assert brain.optim == optimizer
        assert brain.n_layers == 0
        assert len(brain.graph.nodes) == 0
        assert len(brain.graph.edges) == 0
        
        print("âœ… BrainSys inicializado corretamente")

    def test_brain_allocation(self):
        """Testa alocaÃ§Ã£o no BrainSys"""
        print("ðŸ§ª Testando alocaÃ§Ã£o no BrainSys...")
        
        neuratron = Neuratron((100, 50))
        optimizer = torch.optim.Adam(neuratron.parameters(), lr=0.001)
        brain = BrainSys(neuratron, optimizer)
        
        # Aloca algumas camadas
        brain.allocate(20, 10)  # Neura-0
        brain.allocate(10, 5)   # Neura-1
        
        assert brain.n_layers == 2
        assert "Neura-0" in brain.layers.allocations
        assert "Neura-1" in brain.layers.allocations
        assert "Neura-0" in brain.graph.nodes
        assert "Neura-1" in brain.graph.nodes
        
        print("âœ… AlocaÃ§Ã£o no BrainSys funcionando")

    def test_layer_connection(self):
        """Testa conexÃ£o entre camadas"""
        print("ðŸ§ª Testando conexÃ£o entre camadas...")
        
        neuratron = Neuratron((100, 50))
        optimizer = torch.optim.Adam(neuratron.parameters(), lr=0.001)
        brain = BrainSys(neuratron, optimizer)
        
        # Aloca camadas compatÃ­veis
        brain.allocate(20, 10)  # Neura-0
        brain.allocate(10, 5)   # Neura-1
        
        # Conecta as camadas
        brain.connect_layers("Neura-0", "Neura-1", prob=0.8)
        
        assert brain.graph.has_edge("Neura-0", "Neura-1")
        assert brain.graph["Neura-0"]["Neura-1"]["prob"] == 0.8
        
        print("âœ… ConexÃ£o entre camadas funcionando")

    def test_incompatible_connection(self):
        """Testa tentativa de conexÃ£o incompatÃ­vel"""
        print("ðŸ§ª Testando conexÃ£o incompatÃ­vel...")
        
        neuratron = Neuratron((100, 50))
        optimizer = torch.optim.Adam(neuratron.parameters(), lr=0.001)
        brain = BrainSys(neuratron, optimizer)
        
        # Aloca camadas INcompatÃ­veis
        brain.allocate(20, 10)  # Neura-0
        brain.allocate(15, 5)   # Neura-1 (incompatÃ­vel: espera 15, mas Neura-0 produz 10)
        
        try:
            brain.connect_layers("Neura-0", "Neura-1", prob=0.8)
            assert False, "Deveria ter falhado"
        except ValueError as e:
            assert "Incompatibilidade dimensional" in str(e)
        
        print("âœ… PrevenÃ§Ã£o de conexÃ£o incompatÃ­vel funcionando")

    def test_automatic_connection_generation(self):
        """Testa geraÃ§Ã£o automÃ¡tica de conexÃµes"""
        print("ðŸ§ª Testando geraÃ§Ã£o automÃ¡tica de conexÃµes...")
        
        neuratron = Neuratron((100, 50))
        optimizer = torch.optim.Adam(neuratron.parameters(), lr=0.001)
        brain = BrainSys(neuratron, optimizer)
        
        # Aloca vÃ¡rias camadas compatÃ­veis
        brain.allocate(20, 10)  # Neura-0
        brain.allocate(10, 8)   # Neura-1
        brain.allocate(8, 5)    # Neura-2
        brain.allocate(5, 3)    # Neura-3
        
        # Gera conexÃµes automaticamente
        brain.generate_connections(connection_prob=1.0)  # 100% de chance
        
        # Deve ter criado vÃ¡rias conexÃµes
        assert len(brain.graph.edges) > 0
        
        print("âœ… GeraÃ§Ã£o automÃ¡tica de conexÃµes funcionando")

    def test_forward_propagation(self):
        """Testa propagaÃ§Ã£o forward atravÃ©s do grafo"""
        print("ðŸ§ª Testando propagaÃ§Ã£o forward...")
        
        neuratron = Neuratron((100, 50))
        optimizer = torch.optim.Adam(neuratron.parameters(), lr=0.001)
        brain = BrainSys(neuratron, optimizer)
        
        # Aloca e conecta camadas
        brain.allocate(10, 8)  # Neura-0
        brain.allocate(8, 5)   # Neura-1
        brain.allocate(5, 3)   # Neura-2
        
        brain.connect_layers("Neura-0", "Neura-1", prob=0.9)
        brain.connect_layers("Neura-1", "Neura-2", prob=0.9)
        
        # Testa forward pass
        x = torch.randn(4, 10)  # batch_size=4, input_size=10
        output = brain.forward("Neura-0", depth=3, X=x)
        print(output[0].shape)
        
        assert output[0].shape == (4, 3)  # Deve passar por 2 camadas: 10â†’8â†’5â†’3
        
        print("âœ… PropagaÃ§Ã£o forward funcionando")

    def test_training_loop(self):
        """Testa loop de treinamento completo"""
        print("ðŸ§ª Testando loop de treinamento...")
        
        neuratron = Neuratron((50, 30))
        optimizer = torch.optim.Adam(neuratron.parameters(), lr=0.001)
        brain = BrainSys(neuratron, optimizer)
        
        # Configura arquitetura
        brain.allocate(10, 8)  # Neura-0
        brain.allocate(8, 5)   # Neura-1
        brain.connect_layers("Neura-0", "Neura-1", prob=0.9)
        
        # Dados de treino
        x_train = torch.randn(16, 10)
        y_train = torch.randn(16, 5)
        
        # Loop de treino
        losses = []
        for epoch in range(5):
            optimizer.zero_grad()
            output = brain.forward("Neura-0", depth=2, X=x_train)
            loss = F.mse_loss(output[0], y_train)
            loss.backward()
            optimizer.step()
            
            losses.append(loss.item())
        
        # Verifica se o loss diminuiu
        assert losses[-1] < losses[0] or abs(losses[-1] - losses[0]) < 1.0
        
        print("âœ… Loop de treinamento funcionando")

    def test_graph_visualization(self):
        """Testa a visualizaÃ§Ã£o do grafo (sem mostrar)"""
        print("ðŸ§ª Testando visualizaÃ§Ã£o do grafo...")
        
        neuratron = Neuratron((50, 30))
        optimizer = torch.optim.Adam(neuratron.parameters(), lr=0.001)
        brain = BrainSys(neuratron, optimizer)
        
        # Cria uma arquitetura simples
        brain.allocate(10, 8)
        brain.allocate(8, 5)
        brain.connect_layers("Neura-0", "Neura-1", prob=0.7)
        
        # Apenas verifica se a funÃ§Ã£o existe e nÃ£o quebra
        try:
            # NÃ£o mostra o grÃ¡fico durante os testes
            import matplotlib
            matplotlib.use('Agg')  # Usa backend nÃ£o-interativo
            brain.visualize_learning()
            print("âœ… VisualizaÃ§Ã£o do grafo funcionando (backend nÃ£o-interativo)")
        except ImportError:
            print("âš ï¸  Matplotlib nÃ£o disponÃ­vel, pulando teste de visualizaÃ§Ã£o")

    def run_all_tests(self):
        """Executa todos os testes do BrainSys"""
        print("\n" + "="*60)
        print("ðŸš€ INICIANDO TESTES DO BRAINSYS")
        print("="*60)
        
        tests = [
            self.test_brainsys_initialization,
            self.test_brain_allocation,
            self.test_layer_connection,
            self.test_incompatible_connection,
            self.test_automatic_connection_generation,
            self.test_forward_propagation,
            self.test_training_loop,
            self.test_graph_visualization
        ]
        
        for test in tests:
            try:
                test()
            except Exception as e:
                print(f"âŒ {test.__name__} FALHOU: {e}")
                raise
        
        print("\nðŸŽ‰ TODOS OS TESTES DO BRAINSYS PASSARAM!")

# Exemplo de uso completo
def example_usage():
    # ConfiguraÃ§Ã£o inicial
    total_size = (300, 300)  # Tensor total de 200x200
    neura = Neuratron(total_size)
    optimizer = optim.Adam(neura.parameters(), lr=0.1, weight_decay=1e-5)
    
    # Cria o sistema cerebral
    brain = BrainSys(neura, optimizer)
    
    # Aloca vÃ¡rias camadas
    layers = []
    for i in range(20):
        input_size = random.choice([10, 20, 30])
        output_size = random.choice([10, 20, 30])
        layer_name = brain.allocate(input_size, output_size)
        layers.append(layer_name)
        print(f"Alocada camada {layer_name}: {input_size} â†’ {output_size}")
    
    # Gera conexÃµes aleatÃ³rias
    brain.generate_connections(connection_prob=0.4)
    print(f"\nGeradas {brain.graph.number_of_edges()} conexÃµes iniciais")
    
    # Loop de treinamento simulado
    num_episodes = 1000
    
    for episode in range(num_episodes):
        # Gera dados de entrada aleatÃ³rios
        batch_size = 32
        input_size = brain.layers.allocations[layers[0]][0][1] - brain.layers.allocations[layers[0]][0][0]
        X = torch.randn(batch_size, input_size)
        
        depth = random.randint(2, 10)  # Em vez de depth fixo=3
        # Forward pass atravÃ©s do grafo
        output, path_taken = brain.forward(layers[0], depth=depth, X=X)
        
        # Simula uma tarefa de classificaÃ§Ã£o (exemplo)
        target = torch.randint(0, 2, (batch_size, output.shape[1])).float()
        
        # Calcula perda
        loss = nn.MSELoss()(output, target)
        
        # Backpropagation para pesos das camadas
        brain.backprop(loss)
        
        # Calcula recompensa baseada na performance (1 - loss normalizada)
        reward = max(0, 1 - loss.item() * 10)  # Recompensa entre 0 e 1
        
        # â­ ATUALIZAÃ‡ÃƒO DINÃ‚MICA DAS CONEXÃ•ES â­
        brain.update_connection_strengths(reward, path_taken)
        
        if episode % 10 == 0:
            print(f"EpisÃ³dio {episode}: Loss={loss.item():.4f}, Recompensa={reward:.3f}")
    
    # Visualiza resultados
    brain.print_connection_stats()
    
    # Mostra grafo final
    brain.visualize_learning()

def run_comprehensive_test():
    """Executa todos os testes comprehensive"""
    print("ðŸ§ª INICIANDO TESTES COMPLETOS DO SISTEMA")
    print("="*60)
    
    # Testa Neuratron
    neuratron_tester = TestNeuratron()
    neuratron_tester.run_all_tests()
    
    # Testa BrainSys
    brainsys_tester = TestBrainSys()
    brainsys_tester.run_all_tests()
    
    print("\n" + "="*60)
    print("ðŸŽ‰ TODOS OS TESTES PASSARAM! SISTEMA FUNCIONAL!")
    print("="*60)



if __name__ == "__main__":
    # Configura reproduibilidade para testes
    torch.manual_seed(42)
    random.seed(42)
    np.random.seed(42)
    
    try:
        run_comprehensive_test()
    except Exception as e:
        print(f"\nâŒ ERRO CRÃTICO NOS TESTES: {e}")
        import traceback
        traceback.print_exc()
        sys.exit(1)

    example_usage()
